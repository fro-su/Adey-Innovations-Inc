{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv1D, LSTM, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:04:45 INFO mlflow.tracking.fluent: Experiment with name 'Fraud Detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Firew%20Ayele/Desktop/kifiya/Adey-Innovations-Inc/notebooks/mlruns/969604978361663413', creation_time=1729609485785, experiment_id='969604978361663413', last_update_time=1729609485785, lifecycle_stage='active', name='Fraud Detection', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_experiment(\"Fraud Detection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "credit_card_data = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151107</th>\n",
       "      <td>345170</td>\n",
       "      <td>2015-01-27 03:03:34</td>\n",
       "      <td>2015-03-29 00:30:47</td>\n",
       "      <td>43</td>\n",
       "      <td>XPSKTWGPWINLR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>3.451155e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151108</th>\n",
       "      <td>274471</td>\n",
       "      <td>2015-05-15 17:43:29</td>\n",
       "      <td>2015-05-26 12:24:39</td>\n",
       "      <td>35</td>\n",
       "      <td>LYSFABUCPCGBA</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>2.439047e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151109</th>\n",
       "      <td>368416</td>\n",
       "      <td>2015-03-03 23:07:31</td>\n",
       "      <td>2015-05-20 07:07:47</td>\n",
       "      <td>40</td>\n",
       "      <td>MEQHCSJUBRBFE</td>\n",
       "      <td>SEO</td>\n",
       "      <td>IE</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>2.748471e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151110</th>\n",
       "      <td>207709</td>\n",
       "      <td>2015-07-09 20:06:07</td>\n",
       "      <td>2015-09-07 09:34:46</td>\n",
       "      <td>46</td>\n",
       "      <td>CMCXFGRHYSTVJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>3.601175e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151111</th>\n",
       "      <td>138208</td>\n",
       "      <td>2015-06-10 07:02:20</td>\n",
       "      <td>2015-07-21 02:03:53</td>\n",
       "      <td>20</td>\n",
       "      <td>ZINIADFCLHYPG</td>\n",
       "      <td>Direct</td>\n",
       "      <td>IE</td>\n",
       "      <td>M</td>\n",
       "      <td>38</td>\n",
       "      <td>4.103825e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151112 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0         22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1        333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2          1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3        150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4        221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "...         ...                  ...                  ...             ...   \n",
       "151107   345170  2015-01-27 03:03:34  2015-03-29 00:30:47              43   \n",
       "151108   274471  2015-05-15 17:43:29  2015-05-26 12:24:39              35   \n",
       "151109   368416  2015-03-03 23:07:31  2015-05-20 07:07:47              40   \n",
       "151110   207709  2015-07-09 20:06:07  2015-09-07 09:34:46              46   \n",
       "151111   138208  2015-06-10 07:02:20  2015-07-21 02:03:53              20   \n",
       "\n",
       "            device_id  source browser sex  age    ip_address  class  \n",
       "0       QVPSPJUOCKZAR     SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1       EOGFQPIZPYXFZ     Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2       YSSKYOSJHPPLJ     SEO   Opera   M   53  2.621474e+09      1  \n",
       "3       ATGTXKYKUDUQN     SEO  Safari   M   41  3.840542e+09      0  \n",
       "4       NAUITBZFJKHWW     Ads  Safari   M   45  4.155831e+08      0  \n",
       "...               ...     ...     ...  ..  ...           ...    ...  \n",
       "151107  XPSKTWGPWINLR     SEO  Chrome   M   28  3.451155e+09      1  \n",
       "151108  LYSFABUCPCGBA     SEO  Safari   M   32  2.439047e+09      0  \n",
       "151109  MEQHCSJUBRBFE     SEO      IE   F   26  2.748471e+09      0  \n",
       "151110  CMCXFGRHYSTVJ     SEO  Chrome   M   37  3.601175e+09      0  \n",
       "151111  ZINIADFCLHYPG  Direct      IE   M   38  4.103825e+09      0  \n",
       "\n",
       "[151112 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in fraud_data: Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
      "       'device_id', 'source', 'browser', 'sex', 'age', 'ip_address', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Inspect columns of fraud_data\n",
    "print(\"Columns in fraud_data:\", fraud_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime strings to datetime objects\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "# Extract useful datetime components\n",
    "fraud_data['signup_hour'] = fraud_data['signup_time'].dt.hour\n",
    "fraud_data['signup_day'] = fraud_data['signup_time'].dt.dayofweek\n",
    "fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Drop the original datetime columns\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Fraud_Data.csv\n",
    "X_fraud = fraud_data.drop(columns=['class'])\n",
    "y_fraud = fraud_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess creditcard.csv\n",
    "X_cc = credit_card_data.drop(columns=['Class'])\n",
    "y_cc = credit_card_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud)\n",
    "X_train_cc, X_test_cc, y_train_cc, y_test_cc = train_test_split(X_cc, y_cc, test_size=0.2, random_state=42, stratify=y_cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns if any\n",
    "if 'TransactionDate' in X_train_fraud.columns:  # Replace with your datetime column\n",
    "    X_train_fraud['TransactionDate'] = pd.to_datetime(X_train_fraud['TransactionDate'])\n",
    "    X_train_fraud['TransactionYear'] = X_train_fraud['TransactionDate'].dt.year\n",
    "    X_train_fraud['TransactionMonth'] = X_train_fraud['TransactionDate'].dt.month\n",
    "    X_train_fraud['TransactionDay'] = X_train_fraud['TransactionDate'].dt.day\n",
    "    X_train_fraud['TransactionHour'] = X_train_fraud['TransactionDate'].dt.hour\n",
    "    # Drop the original datetime column\n",
    "    X_train_fraud = X_train_fraud.drop('TransactionDate', axis=1)\n",
    "\n",
    "# Repeat for X_test_fraud if needed\n",
    "\n",
    "# Select only numeric columns for scaling\n",
    "numeric_cols_fraud = X_train_fraud.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_cols_cc = X_train_cc.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_fraud_scaled = scaler.fit_transform(X_train_fraud[numeric_cols_fraud])\n",
    "X_test_fraud_scaled = scaler.transform(X_test_fraud[numeric_cols_fraud])\n",
    "\n",
    "X_train_cc_scaled = scaler.fit_transform(X_train_cc[numeric_cols_cc])\n",
    "X_test_cc_scaled = scaler.transform(X_test_cc[numeric_cols_cc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Evaluation Function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_metrics(model_name, accuracy, precision, recall, f1, roc_auc):\n",
    "    mlflow.log_param(\"Model\", model_name)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"F1 Score\", f1)\n",
    "    mlflow.log_metric(\"ROC-AUC\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        log_metrics(model_name, accuracy, precision, recall, f1, roc_auc)\n",
    "        \n",
    "    print(f\"{model_name} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}, ROC-AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier(max_iter=500)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id             int64\n",
      "purchase_value      int64\n",
      "device_id          object\n",
      "source             object\n",
      "browser            object\n",
      "sex                object\n",
      "age                 int64\n",
      "ip_address        float64\n",
      "signup_hour         int32\n",
      "signup_day          int32\n",
      "purchase_hour       int32\n",
      "purchase_day        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns\n",
    "print(X_train_fraud.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encode 'sex' column\n",
    "label_encoder = LabelEncoder()\n",
    "X_train_fraud['sex'] = label_encoder.fit_transform(X_train_fraud['sex'])\n",
    "X_test_fraud['sex'] = label_encoder.transform(X_test_fraud['sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding for 'device_id', 'source', and 'browser'\n",
    "for col in ['device_id', 'source', 'browser']:\n",
    "    freq_encoding = X_train_fraud[col].value_counts(normalize=True)\n",
    "    X_train_fraud[col] = X_train_fraud[col].map(freq_encoding)\n",
    "    X_test_fraud[col] = X_test_fraud[col].map(freq_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Target encode 'device_id', 'source', and 'browser'\n",
    "target_encoder = TargetEncoder(cols=['device_id', 'source', 'browser'])\n",
    "X_train_fraud = target_encoder.fit_transform(X_train_fraud, y_train_fraud)\n",
    "X_test_fraud = target_encoder.transform(X_test_fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode only the top N frequent categories and group others\n",
    "N = 10  # Choose the number of top categories to keep\n",
    "\n",
    "for col in ['device_id', 'source', 'browser']:\n",
    "    top_categories = X_train_fraud[col].value_counts().nlargest(N).index\n",
    "    X_train_fraud[col] = X_train_fraud[col].where(X_train_fraud[col].isin(top_categories), other='Other')\n",
    "    X_test_fraud[col] = X_test_fraud[col].where(X_test_fraud[col].isin(top_categories), other='Other')\n",
    "\n",
    "# Then, apply one-hot encoding after reducing categories\n",
    "X_train_fraud = pd.get_dummies(X_train_fraud, columns=['device_id', 'source', 'browser'], drop_first=True)\n",
    "X_test_fraud = pd.get_dummies(X_test_fraud, columns=['device_id', 'source', 'browser'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Firew Ayele\\Desktop\\kifiya\\Adey-Innovations-Inc\\.venv_adey\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/22 18:44:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.9063627039010026, Precision: 0.0, Recall: 0.0, F1: 0.0, ROC-AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:44:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.641498196737584, Precision: 0.15670297624153015, Recall: 0.6455830388692579, F1: 0.2521913175512458, ROC-AUC: 0.6433296131081953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:46:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.5926612182774708, Precision: 0.14252318829650856, Recall: 0.6678445229681979, F1: 0.23491392703996022, ROC-AUC: 0.6263692369887899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:47:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\FIREWA~1\\AppData\\Local\\Temp\\tmpj3wlk3x3\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/22 18:47:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Accuracy: 0.18654666975482248, Precision: 0.0882698058215678, Recall: 0.8240282685512368, F1: 0.1594584430236931, ROC-AUC: 0.4723580177494986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Firew Ayele\\Desktop\\kifiya\\Adey-Innovations-Inc\\.venv_adey\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/22 18:48:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\FIREWA~1\\AppData\\Local\\Temp\\tmpe9omqr6g\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/22 18:48:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Accuracy: 0.9063627039010026, Precision: 0.0, Recall: 0.0, F1: 0.0, ROC-AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Firew Ayele\\Desktop\\kifiya\\Adey-Innovations-Inc\\.venv_adey\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/10/22 18:48:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.9990344440153085, Precision: 0.7009345794392523, Recall: 0.7653061224489796, F1: 0.7317073170731707, ROC-AUC: 0.8823716881237583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:49:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.9990871107053826, Precision: 0.7346938775510204, Recall: 0.7346938775510204, F1: 0.7346938775510204, ROC-AUC: 0.8671183231311658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 18:59:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.9995611109160493, Precision: 0.9397590361445783, Recall: 0.7959183673469388, F1: 0.861878453038674, ROC-AUC: 0.8979152191264801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 19:10:32 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\FIREWA~1\\AppData\\Local\\Temp\\tmpi2j_g4g8\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/22 19:10:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Accuracy: 0.9983146659176293, Precision: 0.5294117647058824, Recall: 0.1836734693877551, F1: 0.2727272727272727, ROC-AUC: 0.5916960481435117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 19:11:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\FIREWA~1\\AppData\\Local\\Temp\\tmplveyoo64\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/22 19:11:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Accuracy: 0.9987886661282961, Precision: 0.6141732283464567, Recall: 0.7959183673469388, F1: 0.6933333333333334, ROC-AUC: 0.8975283311129741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate on Fraud_Data.csv\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model, X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud, model_name)\n",
    "\n",
    "# Train and evaluate on creditcard.csv\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model, X_train_cc, X_test_cc, y_train_cc, y_test_cc, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_adey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
